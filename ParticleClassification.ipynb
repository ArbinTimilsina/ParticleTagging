{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Particle Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download = True\n",
    "develop = True\n",
    "\n",
    "if download:\n",
    "    if develop:\n",
    "        !wget http://www.stanford.edu/~kterao/public_data/v0.1.0/2d/classification/five_particles/practice_train_5k.root -O InputFiles/classification_train.root\n",
    "        !wget http://www.stanford.edu/~kterao/public_data/v0.1.0/2d/classification/five_particles/practice_test_5k.root -O InputFiles/classification_test.root\n",
    "        !wget http://www.stanford.edu/~kterao/public_data/v0.1.0/2d/segmentation/multipvtx/practice_train_2k.root -O InputFiles/segmentation_train.root\n",
    "        !wget http://www.stanford.edu/~kterao/public_data/v0.1.0/2d/segmentation/multipvtx/practice_test_2k.root -O InputFiles/segmentation_test.root\n",
    "    else:\n",
    "        !wget http://www.stanford.edu/~kterao/public_data/v0.1.0/2d/classification/five_particles/train_50k.root -O InputFiles/classification_train.root\n",
    "        !wget http://www.stanford.edu/~kterao/public_data/v0.1.0/2d/classification/five_particles/test_40k.root -O InputFiles/classification_test.root\n",
    "        !wget http://www.stanford.edu/~kterao/public_data/v0.1.0/2d/segmentation/multipvtx/train_15k.root -O InputFiles/segmentation_train.root\n",
    "        !wget http://www.stanford.edu/~kterao/public_data/v0.1.0/2d/segmentation/multipvtx/test_10k.root -O InputFiles/segmentation_test.root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ROOT\n",
    "from larcv import larcv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import PlottingTools as pt\n",
    "%matplotlib inline \n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import ImageFile                            \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True          \n",
    "\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras.applications.inception_v3 import InceptionV3 \n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from keras import backend as K\n",
    "print '\\nData format for Keras is:', K.image_data_format()\n",
    "\n",
    "!rm -rf Plots/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common variables for all models\n",
    "epochs = 20\n",
    "batchSize = 25\n",
    "\n",
    "imageLength = 256\n",
    "imageHeight = 256\n",
    "\n",
    "# Stop training when a monitored quantity has stopped improving after 20 epochs\n",
    "earlyStop = EarlyStopping(patience=20, verbose=1)\n",
    "\n",
    "# Reduce learning rate when a metric has stopped improving\n",
    "reduceLR = ReduceLROnPlateau(factor=0.3, patience=3, cooldown=3, verbose=1)\n",
    "\n",
    "pdgToCategory =  {11   : 0, #electron\n",
    "                  22   : 1, #gamma\n",
    "                  13   : 2, #muon\n",
    "                  211  : 3, #pion\n",
    "                  2212 : 4} #proton\n",
    "\n",
    "pdgToParticle =  {11   : 'Electron',\n",
    "                  22   : 'Gamma',\n",
    "                  13   : 'Muon',\n",
    "                  211  : 'Pion',\n",
    "                  2212 : 'Proton'}\n",
    "\n",
    "location = [0, 1, 2, 3, 4]\n",
    "labels = ['electron', 'gamma', 'muon', 'pion', 'proton']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_chain = ROOT.TChain(\"image2d_data_tree\")\n",
    "train_image_chain.AddFile('InputFiles/classification_train.root')\n",
    "print 'Found', train_image_chain.GetEntries(), 'images in training dataset!'\n",
    "\n",
    "test_image_chain = ROOT.TChain(\"image2d_data_tree\")\n",
    "test_image_chain.AddFile('InputFiles/classification_test.root')\n",
    "print 'Found', test_image_chain.GetEntries(), 'images in test dataset!'\n",
    "\n",
    "train_label_chain = ROOT.TChain(\"particle_mctruth_tree\")\n",
    "train_label_chain.AddFile('InputFiles/classification_train.root')\n",
    "print 'Found', train_label_chain.GetEntries(), 'labels in training dataset!'\n",
    "\n",
    "test_label_chain = ROOT.TChain(\"particle_mctruth_tree\")\n",
    "test_label_chain.AddFile('InputFiles/classification_test.root')\n",
    "print 'Found', test_label_chain.GetEntries(), 'labels in test dataset!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize training images in detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_view_range(image2d):\n",
    "    nz_pixels=np.where(image2d>=0.0)\n",
    "    ylim = (np.min(nz_pixels[0])-5,np.max(nz_pixels[0])+5)\n",
    "    xlim = (np.min(nz_pixels[1])-5,np.max(nz_pixels[1])+5)\n",
    "    # Adjust for allowed image range\n",
    "    ylim = (np.max((ylim[0],0)), np.min((ylim[1],image2d.shape[1]-1)))\n",
    "    xlim = (np.max((xlim[0],0)), np.min((xlim[1],image2d.shape[0]-1)))\n",
    "    return (xlim,ylim)\n",
    "xAxis=['x', 'y', 'z']\n",
    "yAxis=['y', 'z', 'x']\n",
    "\n",
    "entryList = [x*1002 for x in range(5)]\n",
    "for entry in entryList:\n",
    "    train_image_chain.GetEntry(entry)\n",
    "    image_object = train_image_chain.image2d_data_branch\n",
    "    image_vector = image_object.as_vector()\n",
    "\n",
    "    fig = plt.figure(figsize=(20,5))\n",
    "    for index, image in enumerate(image_vector):\n",
    "        ax = fig.add_subplot(1, 3, index+1)\n",
    "        numpyImage = larcv.as_ndarray(image)\n",
    "        ax.imshow(numpyImage, interpolation='none',cmap='ocean_r', origin='lower')\n",
    "        \n",
    "        ax.set_xlabel(xAxis[index], fontsize=20)\n",
    "        ax.set_ylabel(yAxis[index], fontsize=20)\n",
    "        \n",
    "        xlim, ylim = get_view_range(numpyImage)\n",
    "        \n",
    "        # Set range\n",
    "        ax.set_ylim(ylim)\n",
    "        ax.set_xlim(xlim)\n",
    "\n",
    "    train_label_chain.GetEntry(entry)\n",
    "    label_object = train_label_chain.particle_mctruth_branch\n",
    "    for particle in label_object.as_vector():\n",
    "        fig.suptitle('Training images: {}'.format(pdgToParticle[particle.pdg_code()]), fontsize=20)\n",
    "        plt.show()\n",
    "        fig.savefig('Plots/ClassificationTrainingImage{}.pdf'.format(pdgToParticle[particle.pdg_code()]), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools to preprocess the images and labels for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageToTensor(imageToConvert):\n",
    "    # imageToConvert is a C++ class larcv::EventImage2D exposed to python interpreter\n",
    "    # Note here that std::vectors in pyroot are iterable\n",
    "    array2D = imageToConvert.as_vector()\n",
    "    \n",
    "    array3D = []\n",
    "    for _, image in enumerate(array2D):\n",
    "        # larcv has a helper function to convert std::vector to numpy array, so we can use that:\n",
    "        numpyImage = larcv.as_ndarray(image)\n",
    "        array3D.append(numpyImage)        \n",
    "    tensor3D = np.dstack((array3D[0], array3D[1], array3D[2]))\n",
    "\n",
    "    # Convert 3D tensor to 4D tensor with shape (1, imageLength, imageHeight, 3) and return 4D tensor\n",
    "    return tensor3D#np.expand_dims(tensor3D, axis=0)\n",
    "\n",
    "def imageChainToTensor(imageChain):\n",
    "    listOfTensors = []\n",
    "    for entry in tqdm(xrange(imageChain.GetEntries())):\n",
    "        imageChain.GetEntry(entry)\n",
    "        entryData = imageChain.image2d_data_branch\n",
    "        listOfTensors.append(imageToTensor(entryData))\n",
    "    return np.array(listOfTensors)\n",
    "\n",
    "def labelChainToArray(labelChain):\n",
    "    listOfLabels = []\n",
    "    for entry in tqdm(xrange(labelChain.GetEntries())):\n",
    "        labelChain.GetEntry(entry)\n",
    "        entryData = labelChain.particle_mctruth_branch\n",
    "        arrayParticle = entryData.as_vector()\n",
    "        for _, particle in enumerate(arrayParticle):\n",
    "            listOfLabels.append(pdgToCategory[particle.pdg_code()])\n",
    "    return np.array(listOfLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert every images to 4D tensors\n",
    "X_train = imageChainToTensor(train_image_chain)\n",
    "X_test = imageChainToTensor(test_image_chain)\n",
    "\n",
    "print X_train[0].shape\n",
    "print X_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 5 different particle types in the dataset\n",
    "num_classes = 5\n",
    "trainLabelArray = labelChainToArray(train_label_chain)\n",
    "testLabelArray = labelChainToArray(test_label_chain)\n",
    "\n",
    "y_train = np_utils.to_categorical(trainLabelArray, num_classes)\n",
    "y_test = np_utils.to_categorical(testLabelArray, num_classes)\n",
    "print y_train[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarkModel = Sequential()\n",
    "\n",
    "benchmarkModel.add(Conv2D(filters=16, kernel_size=3, padding='same', activation='relu',input_shape=X_train[0].shape))\n",
    "benchmarkModel.add(BatchNormalization())\n",
    "benchmarkModel.add(MaxPooling2D(pool_size=2))\n",
    "benchmarkModel.add(Dropout(0.65))\n",
    "\n",
    "benchmarkModel.add(Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "benchmarkModel.add(BatchNormalization())\n",
    "benchmarkModel.add(MaxPooling2D(pool_size=2))\n",
    "benchmarkModel.add(Dropout(0.65))\n",
    "\n",
    "benchmarkModel.add(Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
    "benchmarkModel.add(BatchNormalization())\n",
    "benchmarkModel.add(MaxPooling2D(pool_size=2))\n",
    "benchmarkModel.add(Dropout(0.65))\n",
    "\n",
    "benchmarkModel.add(Conv2D(filters=128, kernel_size=3, padding='same', activation='relu'))\n",
    "benchmarkModel.add(BatchNormalization())\n",
    "benchmarkModel.add(MaxPooling2D(pool_size=2))\n",
    "benchmarkModel.add(Dropout(0.65))\n",
    "\n",
    "benchmarkModel.add(Flatten())         \n",
    "benchmarkModel.add(Dense(500, activation='relu'))\n",
    "benchmarkModel.add(BatchNormalization())\n",
    "benchmarkModel.add(Dropout(0.5))\n",
    "\n",
    "benchmarkModel.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "benchmarkModel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarkModel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the classification accuracy of the benchmark model (before training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the test accuracy\n",
    "score = benchmarkModel.evaluate(X_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "# Print the test accuracy\n",
    "print('Test accuracy of the benchmark model (before training): %.4f%%' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model after every epoch\n",
    "checkPoint = ModelCheckpoint(filepath='SavedModels/ClassificationBenchmarkBest.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "history = benchmarkModel.fit(X_train, y_train, batch_size=batchSize, epochs=epochs,\n",
    "          validation_split=0.20, callbacks=[checkPoint, earlyStop, reduceLR],\n",
    "          verbose=0, shuffle=True)\n",
    "\n",
    "# Summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Benchmark model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper left')\n",
    "plt.savefig('Plots/ClassificationBenchmarkAccuracy.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Benchmark model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper left')\n",
    "plt.savefig('Plots/ClassificationBenchmarkLoss.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the classification accuracy of the model (after training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model with the best classification accuracy on the validation set\n",
    "benchmarkModel.load_weights('SavedModels/ClassificationBenchmarkBest.hdf5')\n",
    "\n",
    "# Calculate the classification accuracy on the test set\n",
    "score = benchmarkModel.evaluate(X_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "# Print the test accuracy\n",
    "print('Test accuracy of the benchmark model (after training): %.4f%%' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the result of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = benchmarkModel.predict(X_test, verbose = False)\n",
    "\n",
    "y_p = []\n",
    "for y in y_pred:\n",
    "    y_p.append(np.argmax(y))\n",
    "y_t = []\n",
    "for t in y_test:\n",
    "    y_t.append(np.argmax(t))\n",
    "\n",
    "fig, ax1 = plt.subplots(1,1, figsize = (6,6))\n",
    "ax1.hist2d(y_t, y_p, bins=(25, 25), cmap=plt.cm.Greys)\n",
    "ax1.plot(y_t, y_t, 'r-', label = 'True')\n",
    "plt.xticks(location, labels)\n",
    "plt.yticks(location, labels)\n",
    "\n",
    "ax1.legend()\n",
    "ax1.set_title('Benchmark model', fontsize=25)\n",
    "ax1.set_xlabel('True particle', fontsize=20)\n",
    "ax1.set_ylabel('Predicted particle', fontsize=20)\n",
    "pt.setTicks(ax1)\n",
    "\n",
    "fig.savefig('Plots/ClassificationBenchmarkResult.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model based on InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load InceptionV3 model + remove final classification layers\n",
    "baseModel = InceptionV3(weights='imagenet', include_top=False, input_shape=(imageLength, imageHeight, 3))\n",
    "\n",
    "# Add a global average pooling layer\n",
    "myLayers = baseModel.output\n",
    "myLayers = GlobalAveragePooling2D()(myLayers)\n",
    "myLayers = Dropout(0.5)(myLayers)\n",
    "\n",
    "# A fully connected layer\n",
    "myLayers = Dense(1000, activation='relu')(myLayers)\n",
    "myLayers = Dropout(0.5)(myLayers)\n",
    "\n",
    "# Output layer\n",
    "predictions = Dense(num_classes, activation='softmax')(myLayers)\n",
    "\n",
    "# The model\n",
    "InceptionV3Model = Model(inputs=baseModel.input, outputs=predictions)\n",
    "\n",
    "# Freeze all convolutional InceptionV3 layers\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "InceptionV3Model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "InceptionV3Model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model after every epoch\n",
    "checkPoint = ModelCheckpoint(filepath='SavedModels/ClassificationInceptionV3BottleneckBest.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "history = InceptionV3Model.fit(X_train, y_train, batch_size=batchSize, epochs=epochs,\n",
    "                               validation_split=0.20, callbacks=[checkPoint, earlyStop, reduceLR],\n",
    "                               verbose=0, shuffle=True)\n",
    "\n",
    "# Summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('InceptionV3 bottleneck model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper left')\n",
    "plt.savefig('Plots/ClassificationInceptionV3BottleneckAccuracy.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('InceptionV3 bottleneck model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper left')\n",
    "plt.savefig('Plots/ClassificationInceptionV3BottleneckLoss.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the classification accuracy of the model (after training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model with the best classification accuracy on the validation set\n",
    "InceptionV3Model.load_weights('SavedModels/ClassificationInceptionV3BottleneckBest.hdf5')\n",
    "\n",
    "# Calculate the classification accuracy on the test set\n",
    "score = InceptionV3Model.evaluate(X_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "# Print the test accuracy\n",
    "print('Test accuracy of the model (after training): %.4f%%' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the result of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = InceptionV3Model.predict(X_test, verbose = False)\n",
    "\n",
    "y_p = []\n",
    "for y in y_pred:\n",
    "    y_p.append(np.argmax(y))\n",
    "y_t = []\n",
    "for t in y_test:\n",
    "    y_t.append(np.argmax(t))\n",
    "\n",
    "fig, ax1 = plt.subplots(1,1, figsize = (6,6))\n",
    "ax1.hist2d(y_t, y_p, bins=(25, 25), cmap=plt.cm.Greys)\n",
    "ax1.plot(y_t, y_t, 'r-', label = 'True')\n",
    "plt.xticks(location, labels)\n",
    "plt.yticks(location, labels)\n",
    "\n",
    "ax1.legend()\n",
    "ax1.set_title('InceptionV3 bottleneck model', fontsize=25)\n",
    "ax1.set_xlabel('True particle', fontsize=20)\n",
    "ax1.set_ylabel('Predicted particle', fontsize=20)\n",
    "pt.setTicks(ax1)\n",
    "\n",
    "fig.savefig('Plots/ClassificationInceptionV3BottleneckResult.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize layer names and layer indices to see how many layers to freeze (to fine-tune the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(baseModel.layers):\n",
    "   print i, layer.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the top few inception blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's train the top 3 inception blocks\n",
    "# Freeze the first 229 layers\n",
    "for layer in InceptionV3Model.layers[:229]:\n",
    "   layer.trainable = False\n",
    "for layer in InceptionV3Model.layers[229:]:\n",
    "   layer.trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "InceptionV3Model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.005, momentum=0.9), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model after every epoch\n",
    "checkPoint = ModelCheckpoint(filepath='SavedModels/ClassificationInceptionV3FineTunedBest.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "history = InceptionV3Model.fit(X_train, y_train, batch_size=batchSize, epochs=epochs,\n",
    "                               validation_split=0.20, callbacks=[checkPoint, earlyStop, reduceLR],\n",
    "                               verbose=0, shuffle=True)\n",
    "\n",
    "# Summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('InceptionV3 fine-tuned model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper left')\n",
    "plt.savefig('Plots/ClassificationInceptionV3FineTunedAccuracy.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('InceptionV3 fine-tune model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper left')\n",
    "plt.savefig('Plots/ClassificationInceptionV3FineTunedAccuracy.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the classification accuracy of the model (after training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model with the best classification accuracy on the validation set\n",
    "InceptionV3Model.load_weights('SavedModels/ClassificationInceptionV3FineTunedBest.hdf5')\n",
    "\n",
    "# Calculate the classification accuracy on the test set\n",
    "score = InceptionV3Model.evaluate(X_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "# Print the test accuracy\n",
    "print('Test accuracy of the model (after training): %.4f%%' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the result of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = InceptionV3Model.predict(X_test, verbose = False)\n",
    "\n",
    "y_p = []\n",
    "for y in y_pred:\n",
    "    y_p.append(np.argmax(y))\n",
    "y_t = []\n",
    "for t in y_test:\n",
    "    y_t.append(np.argmax(t))\n",
    "\n",
    "fig, ax1 = plt.subplots(1,1, figsize = (6,6))\n",
    "ax1.hist2d(y_t, y_p, bins=(25, 25), cmap=plt.cm.Greys)\n",
    "ax1.plot(y_t, y_t, 'r-', label = 'True')\n",
    "plt.xticks(location, labels)\n",
    "plt.yticks(location, labels)\n",
    "\n",
    "ax1.legend()\n",
    "ax1.set_title('InceptionV3 fine-tune model', fontsize=25)\n",
    "ax1.set_xlabel('True particle', fontsize=20)\n",
    "ax1.set_ylabel('Predicted particle', fontsize=20)\n",
    "pt.setTicks(ax1)\n",
    "\n",
    "fig.savefig('Plots/ClassificationInceptionV3FineTunedResult.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_chain = ROOT.TChain(\"image2d_data_tree\")\n",
    "train_image_chain.AddFile('InputFiles/segmentation_train.root')\n",
    "print 'Found', train_image_chain.GetEntries(), 'images in training dataset!'\n",
    "\n",
    "test_image_chain = ROOT.TChain(\"image2d_data_tree\")\n",
    "test_image_chain.AddFile('InputFiles/segmentation_test.root')\n",
    "print 'Found', test_image_chain.GetEntries(), 'images in test dataset!'\n",
    "\n",
    "train_label_chain = ROOT.TChain(\"image2d_segment_tree\")\n",
    "train_label_chain.AddFile('InputFiles/segmentation_train.root')\n",
    "print 'Found', train_label_chain.GetEntries(), 'labels in training dataset!'\n",
    "\n",
    "test_label_chain = ROOT.TChain(\"image2d_segment_tree\")\n",
    "test_label_chain.AddFile('InputFiles/segmentation_test.root')\n",
    "print 'Found', test_label_chain.GetEntries(), 'labels in test dataset!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize a single training image: Background + Shower + Track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry = 552\n",
    "train_image_chain.GetEntry(entry)\n",
    "train_label_chain.GetEntry(entry)\n",
    "\n",
    "# Let's grab a specific projection (1st one)\n",
    "image2d = larcv.as_ndarray(train_image_chain.image2d_data_branch.as_vector().front())\n",
    "label2d = larcv.as_ndarray(train_label_chain.image2d_segment_branch.as_vector().front())\n",
    "\n",
    "categories = ['Background','Shower','Track']\n",
    "unique_values, unique_counts = np.unique(label2d, return_counts=True)\n",
    "\n",
    "fig, axes = plt.subplots(1, len(unique_values), figsize=(18,12), facecolor='w')\n",
    "xlim,ylim = get_view_range(image2d)\n",
    "for index, value in enumerate(unique_values):\n",
    "    ax = axes[index]\n",
    "    mask = (label2d == value)\n",
    "    ax.imshow(image2d * mask, interpolation='none', cmap='gist_heat_r', origin='lower')\n",
    "    ax.set_title(categories[index],fontsize=20,fontname='Georgia',fontweight='bold')\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylim(ylim)\n",
    "plt.show()\n",
    "fig.savefig('Plots/SegmentationTrainingImageSeparated.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize a single training image and label in detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump images\n",
    "fig, (ax0,ax1) = plt.subplots(1, 2, figsize=(15,10), facecolor='w')\n",
    "ax0.imshow(image2d, interpolation='none', cmap='gist_heat_r', origin='lower')\n",
    "ax1.imshow(label2d, interpolation='none', cmap='gist_heat_r', origin='lower',vmin=0., vmax=2.0)\n",
    "ax0.set_title('Data',fontsize=20,fontname='Georgia',fontweight='bold')\n",
    "ax0.set_xlim(xlim)\n",
    "ax0.set_ylim(ylim)\n",
    "ax1.set_title('Label',fontsize=20,fontname='Georgia',fontweight='bold')\n",
    "ax1.set_xlim(xlim)\n",
    "ax1.set_ylim(ylim)\n",
    "plt.show()\n",
    "fig.savefig('Plots/SegmentationTrainingImageAndLabel.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
